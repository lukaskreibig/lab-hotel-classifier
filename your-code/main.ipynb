{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><center>Canceled bookings at a hotel</center></h1>\n",
    "\n",
    "\n",
    "You have been assigned the task of building a model that will predict whether or not a customer of a hotel will cancel their booking. The data for this assingment is found in the csv file `hotel_clf`\n",
    "\n",
    "<br> \n",
    "<div>\n",
    "<img src=\"https://5.imimg.com/data5/PC/BL/MY-33192851/hotel-reservation-services-500x500.jpg\" width=\"400\"/>\n",
    "</div>\n",
    "<br> \n",
    "If the model predicts that a customer will cancel their booking, that customer will be sent a special deal to try to keep the customer from cancel the booking. If the prediction is correct (a True Positive), the expected gain is 1000 SEK. However, if the prediction is wrong (a False Positive), the expected loss is 500 SEK. \n",
    "\n",
    "Your goal is to build the most profitable model possible.\n",
    "\n",
    "<hr style=\"border:1px solid pink\"> </hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q1 | Choose Metric\n",
    "\n",
    "Reason about which metric you think will be best to optimize your model for.\n",
    "\n",
    "- Recall?\n",
    "- Precision?\n",
    "- Accuracy?\n",
    "- F1-score?\n",
    "\n",
    "Make a decision about which metric you think will lead to the most profitable model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Answer\n",
    "\n",
    "If missing cancellations (False Negatives) is costly, we should emphasize Recall.\n",
    "If wrongly flagging cancellations (False Positives) is costly, we should emphasize Precision.\n",
    "Since False Positives incur a loss (-500 SEK) and True Positives bring a gain (+1000 SEK), we want to maximize profit.\n",
    "\n",
    "The optimal trade-off between precision and recall is captured by the F1-score, which is useful when both types of errors are important.\n",
    "\n",
    "Decision: F1-score: is the most balanced and profit-oriented metric in this case."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q2 | Data prepatation\n",
    "\n",
    "- Prepare your data so that you end up with a clean and preprocessed train and test set\n",
    "    \n",
    "    \n",
    "- Instructions for train test split:    \n",
    "    - Test size = 0.2\n",
    "    - Random state = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "df = pd.read_csv(\"../data/hotel_clf.csv\")\n",
    "\n",
    "df = df.dropna(subset=[\"children\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>is_canceled</th>\n",
       "      <th>lead_time</th>\n",
       "      <th>adults</th>\n",
       "      <th>children</th>\n",
       "      <th>booking_changes</th>\n",
       "      <th>adr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>is_canceled</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.315002</td>\n",
       "      <td>0.057276</td>\n",
       "      <td>0.002468</td>\n",
       "      <td>-0.143197</td>\n",
       "      <td>0.033869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lead_time</th>\n",
       "      <td>0.315002</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.128026</td>\n",
       "      <td>-0.038613</td>\n",
       "      <td>-0.029949</td>\n",
       "      <td>-0.054567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>adults</th>\n",
       "      <td>0.057276</td>\n",
       "      <td>0.128026</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.037699</td>\n",
       "      <td>-0.075726</td>\n",
       "      <td>0.177399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>children</th>\n",
       "      <td>0.002468</td>\n",
       "      <td>-0.038613</td>\n",
       "      <td>0.037699</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.052715</td>\n",
       "      <td>0.231473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>booking_changes</th>\n",
       "      <td>-0.143197</td>\n",
       "      <td>-0.029949</td>\n",
       "      <td>-0.075726</td>\n",
       "      <td>0.052715</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.009761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>adr</th>\n",
       "      <td>0.033869</td>\n",
       "      <td>-0.054567</td>\n",
       "      <td>0.177399</td>\n",
       "      <td>0.231473</td>\n",
       "      <td>0.009761</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 is_canceled  lead_time    adults  children  booking_changes  \\\n",
       "is_canceled         1.000000   0.315002  0.057276  0.002468        -0.143197   \n",
       "lead_time           0.315002   1.000000  0.128026 -0.038613        -0.029949   \n",
       "adults              0.057276   0.128026  1.000000  0.037699        -0.075726   \n",
       "children            0.002468  -0.038613  0.037699  1.000000         0.052715   \n",
       "booking_changes    -0.143197  -0.029949 -0.075726  0.052715         1.000000   \n",
       "adr                 0.033869  -0.054567  0.177399  0.231473         0.009761   \n",
       "\n",
       "                      adr  \n",
       "is_canceled      0.033869  \n",
       "lead_time       -0.054567  \n",
       "adults           0.177399  \n",
       "children         0.231473  \n",
       "booking_changes  0.009761  \n",
       "adr              1.000000  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correlation_matrix = df.select_dtypes(include=['number']).corr()\n",
    "correlation_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6815\n",
      "Precision: 0.6518518518518519\n",
      "Recall: 0.3473684210526316\n",
      "F1-Score: 0.4532188841201717\n"
     ]
    }
   ],
   "source": [
    "X = df[[\"lead_time\", \"adults\", \"children\", \"booking_changes\", \"adr\"]]  # pick relevant numeric columns\n",
    "y = df[\"is_canceled\"]  # binary target\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train a logistic regression model\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Calculate metrics\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "prec = precision_score(y_test, y_pred)\n",
    "rec = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "print(\"Accuracy:\", acc)\n",
    "print(\"Precision:\", prec)\n",
    "print(\"Recall:\", rec)\n",
    "print(\"F1-Score:\", f1)\n",
    "\n",
    "# Decide which metric is most profitable based on the cost of false positives vs. false negatives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TP: 264 FP: 141\n",
      "Estimated Profit (SEK): 193500\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "profit = tp * 1000 - fp * 500\n",
    "\n",
    "print(\"TP:\", tp, \"FP:\", fp)\n",
    "print(\"Estimated Profit (SEK):\", profit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q3 | Build a LogReg Model\n",
    "\n",
    "Guidelines:\n",
    "- Use a LogisticRegression model\n",
    "    - Random state = 42\n",
    "- Use the metric you decided on in the previous question\n",
    "\n",
    "- You are not allowed to change the model after looking at the performance on test data\n",
    "- Your models predictions on test data will be translated into SEK. I.e:\n",
    "    - 10 TP = 10 * 1 000 SEK = +10 000 \n",
    "    - 10 FP = 10 * -500 SEK = -5 000 SEK\n",
    "        - Expected Value from model = +5 000 SEK \n",
    "        \n",
    "        \n",
    "After you have trained your model, make predictions for your test data and calculate the profitable of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation F1 scores: [0.5975522  0.62848752 0.62093352 0.60448808 0.58479532]\n",
      "Mean F1 score: 0.6072513272564232\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf_cv = RandomForestClassifier(random_state=42)\n",
    "scores = cross_val_score(rf_cv, X, y, cv=5, scoring='f1')  # or 'precision', 'recall', etc.\n",
    "\n",
    "print(\"Cross-validation F1 scores:\", scores)\n",
    "print(\"Mean F1 score:\", scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RFC - Accuracy: 0.72\n",
      "RFC - Precision: 0.6533742331288344\n",
      "RFC - Recall: 0.5605263157894737\n",
      "RFC - F1-Score: 0.603399433427762\n",
      "RFC - Profit (SEK): 313000\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier(random_state=42)\n",
    "rf.fit(X_train, y_train)\n",
    "y_pred_rf = rf.predict(X_test)\n",
    "\n",
    "acc_rf = accuracy_score(y_test, y_pred_rf)\n",
    "prec_rf = precision_score(y_test, y_pred_rf)\n",
    "rec_rf = recall_score(y_test, y_pred_rf)\n",
    "f1_rf = f1_score(y_test, y_pred_rf)\n",
    "\n",
    "print(\"RFC - Accuracy:\", acc_rf)\n",
    "print(\"RFC - Precision:\", prec_rf)\n",
    "print(\"RFC - Recall:\", rec_rf)\n",
    "print(\"RFC - F1-Score:\", f1_rf)\n",
    "\n",
    "# Profit\n",
    "tn_rf, fp_rf, fn_rf, tp_rf = confusion_matrix(y_test, y_pred_rf).ravel()\n",
    "profit_rf = tp_rf * 1000 - fp_rf * 500\n",
    "print(\"RFC - Profit (SEK):\", profit_rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q4 | Build a RandomForestClassifier model\n",
    "\n",
    "- Use a RandomForestClassifier model:\n",
    "    - random_state = 42\n",
    "\n",
    "\n",
    "- After you have trained your model, make predictions for your test data and calculate the profitable of the model\n",
    "\n",
    "- Which model was more profitable, the LogReg or the RandomForestClassifier?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "More profitable model: RandomForest\n"
     ]
    }
   ],
   "source": [
    "print(\"More profitable model:\", \"LogReg\" if profit > profit_rf else \"RandomForest\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q5 | Did you choose the right metric? \n",
    "\n",
    "Calculate the profitablity for the RandomForestClassifier for all 4 different metrics. Then rank order the outcome. I.e.:\n",
    "\n",
    "- RFC (precision) = 1\n",
    "- RFC (accuracy) = 2\n",
    "- ...\n",
    "- ...\n",
    "\n",
    "\n",
    "***Note:*** You don't have to use a param_grid for this question, just run the RandomForest with default settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'max_depth': None, 'n_estimators': 50}\n",
      "Best score: 0.6012536503927767\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "params = {\n",
    "    'n_estimators': [50, 100],\n",
    "    'max_depth': [5, 10, None]\n",
    "}\n",
    "\n",
    "grid = GridSearchCV(\n",
    "    estimator=RandomForestClassifier(random_state=42),\n",
    "    param_grid=params,\n",
    "    scoring='f1',\n",
    "    cv=5\n",
    ")\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best parameters:\", grid.best_params_)\n",
    "print(\"Best score:\", grid.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. RFC (accuracy) → Profit: 313000 SEK\n",
      "2. RFC (precision) → Profit: 313000 SEK\n",
      "3. RFC (recall) → Profit: 313000 SEK\n",
      "4. RFC (f1) → Profit: 313000 SEK\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "# Helper function\n",
    "def evaluate_profit(y_true, y_pred):\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
    "    return tp * 1000 - fp * 500\n",
    "\n",
    "# Evaluate RFC under each metric\n",
    "metrics = {\n",
    "    'accuracy': accuracy_score,\n",
    "    'precision': precision_score,\n",
    "    'recall': recall_score,\n",
    "    'f1': f1_score\n",
    "}\n",
    "\n",
    "profits = {}\n",
    "for name, scorer in metrics.items():\n",
    "    rf = RandomForestClassifier(random_state=42)\n",
    "    rf.fit(X_train, y_train)\n",
    "    y_pred = rf.predict(X_test)\n",
    "    profit = evaluate_profit(y_test, y_pred)\n",
    "    profits[name] = profit\n",
    "\n",
    "# Sort and print\n",
    "sorted_profits = sorted(profits.items(), key=lambda x: x[1], reverse=True)\n",
    "for rank, (metric, profit) in enumerate(sorted_profits, start=1):\n",
    "    print(f\"{rank}. RFC ({metric}) → Profit: {profit} SEK\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
